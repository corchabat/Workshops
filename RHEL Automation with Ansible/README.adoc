:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

= RHEL Automation with Ansible - Latam Tech Office Workshop series

:numbered:

== Description

In this workshop we will be showing an important part of any platform administration, which is the operating system management. A lot of the tasks with the operating system are manual and repetitive, and impose several disadvantages regarding time spent in such activities, complexity associated to management procedures, lack of control in more complex activities and errors in which the administrator could be involved due to the human nature.

Much has been said and written about the new hybrid and multicloud era. At this moment in time, manual tasks supported by human intervention could be the wrong way to transit, just because the scale and complexity requires assistance to be efficient enough to keep the pace of growing.

The Ansible tool, as described officially defines  "a radically simple IT automation engine that automates cloud provisioning, configuration management, application deployment, intra-service orchestration, and many other IT needs." 

This workshop is aimed to show you how easy is to plan and use ansible for automating the most common administration tasks RHEL could require in a day by day basis.

Also, not so common tasks will be shown in order to give you the tools for your daily work in the datacenter.

== Audience
IT Managers, Architects and technical staff who operates Linux

== Create a virtual Environment for the workshop

=== Install Virtualbox

* Download virtualbox from https://www.virtualbox.org/wiki/Downloads
* Install and configure the host-only network 
* Go to File/Host Network Manager… or Ctrl+H
* Push the create Button
* A Virtualbox Host-Only Ethernet Adapter will be created
* Select it and configure the ip address and mask

image::host_network_manager_ip_mask_config.png[Host network manager ip and mask config]

* Then activate and configure the DHCP server

image::dhcp_activation.png[dhcp server activation]

* Now, all the servers which have a host only network interface configured will be enabled to communicate with each other.
* The virtual machines imported in the next steps have configured 2 network interfaces.
- A NAT interface for internet connection
- A Host Only Network Interface for the internal networking, which is required to communicate the control and managed host.

=== Download the RHEL 8x virtual machine


* Download the unregistered applicance from 
https://1drv.ms/u/s!AjxeDEQoUvfXmgEVes7JRvcp-Hpc?e=FVQN1G[RHEL 8.1 virtual machine (.ova)^]
* Import the MV to VirtualBox.
* Rename the MV to “RHEL8x control node”.
* Boot the server
* Login with user: root, password: ltodemos
* Change the hostname

[source,bash]
-----------------
# hostnamectl set-hostname controlhost
-----------------

* Register the server with your development account. You can get the developer subscription at https://developers.redhat.com/register.

[source,bash]
-----------------
# subscription-manager register --auto-attach
-----------------
* Introduce your username and password with your subscription credentials.
* Update the server

[source,bash]
-----------------
# yum update
-----------------

=== Clone the machine to create a managed host server

* Do a poweroff from the rhel server already installed
* From VirtualBox, select the MV and clone it executing (menu) machine/clone or (Ctrl-O) to clone the server to be a managed host.
* Define a new MAC address policy to a “generate a new MAC address for all network adapters”
* Change the name to “RHEL8x managed host”.
* Boot the server
* Login with user: root, password: ltodemos
* Change the hostname

[source,bash]
-----------------
# hostnamectl set-hostname managedhost
-----------------
* Register the server with your development account

[source,bash]
-----------------
# subscription-manager register --auto-attach
-----------------

* Introduce your username and password with your subscription credentials.

=== Find out the IP addresses of both servers

Login in both servers and check their IP addresses issuing

[source,bash]
-----------------
# ifconfig enp0s8
-----------------

Write down the ip for future references.

=== Document the information of the servers

Fill the table below.

[options="header"]
|=======================
|Server | ip address
|Control host |
|Managed host |
|=======================

[NOTE]
At this point you have 2 servers, a control host and a managed host. These are the servers you need to follow this workshop.

== What is Ansible and how this fits in my daily work?
=== Automation!

As the Encyclopedia Britannica defines, “automation can be defined as a technology concerned with performing a process by means of programmed commands combined with automatic feedback control to ensure proper execution of the instructions. The resulting system is capable of operating without human intervention.” 

Automation has been with us for years, indeed the evolution of humanity is based on the notion of “how do I automate a process with repetitive tasks, in order to be more accurate, precise and fast in the execution”.

History is plagued with stories of automation. Gutenberg Printing Press, The Ford’s production line, Coffee machines, Bread Making Machine, Spotify, Amazon online, etc, etc, etc.

In the IT world, the automation is even more necessary to execute repetitive tasks to bring a system to its usability state. This is where Ansible comes in this movie.

From https://www.ansible.com/overview/how-ansible-works we can rescue the following description:

“Ansible is a radically simple IT automation engine that automates cloud provisioning, configuration management, application deployment, intra-service orchestration, and many other IT needs.”

The vast majority of activities you execute on a daily basis for managing and configuring your RHEL (or any other linux or windows OS) can be expressed as a playbook and done automatically on managed hosts.

The goal of this workshop is to propose to participants a practical view of what Ansible can do for helping administrators and developers execute repetitive tasks on the management side of RHEL, in order to be more productive in less time.

== Some Ansible basics

=== Control node

Any machine with Ansible installed. You can run commands and playbooks, invoking /usr/bin/ansible or /usr/bin/ansible-playbook, from any control node. You can use any computer that has Python installed on it as a control node - laptops, shared desktops, and servers can all run Ansible. However, you cannot use a Windows machine as a control node. You can have multiple control nodes.

=== Managed nodes

The network devices (and/or servers) you manage with Ansible. Managed nodes are also sometimes called “hosts”. Ansible is not installed on managed nodes.

=== Inventory

A list of managed nodes. An inventory file is also sometimes called a “hostfile”. Your inventory can specify information like IP address for each managed node. An inventory can also organize managed nodes, creating and nesting groups for easier scaling.

=== Modules 

The units of code Ansible executes. Each module has a particular use, from administering users on a specific type of database to managing VLAN interfaces on a specific type of network device. You can invoke a single module with a task, or invoke several different modules in a playbook.

=== Tasks

The units of action in Ansible. You can execute a single task once with an ad-hoc command.

=== Playbooks

Ordered lists of tasks, saved so you can run those tasks in that order repeatedly. Playbooks can include variables as well as tasks. Playbooks are written in YAML and are easy to read, write, share and understand. 

=== Places to get more information

|=======================
|https://docs.ansible.com/ansible/latest/network/getting_started/basic_concepts.html
|https://www.ansible.com/overview/how-ansible-work
|=======================

== Preparing the environment
=== Installing the Ansible control host
==== Log In in the Control Node

Use the root account with ltodemos password to log in to this server with the IP logged in previous steps.

[NOTE]
If you are in Windows you can download putty for conveniently create 2 entries for log in to the control and management hosts.

==== Finding the repository
[source,bash]
-----------------
# yum repolist all | grep -i ansible

ansible-2-for-rhel-8-x86_64-debug-rpms     Red Hat Ans disabled
ansible-2-for-rhel-8-x86_64-rpms           Red Hat Ans disabled
ansible-2-for-rhel-8-x86_64-source-rpms    Red Hat Ans disabled
Ansible-2.8-for-rhel-8-x86_64-debug-rpms   Red Hat Ans disabled
ansible-2.8-for-rhel-8-x86_64-rpms         Red Hat Ans disabled
ansible-2.8-for-rhel-8-x86_64-source-rpms  Red Hat Ans disabled
ansible-2.9-for-rhel-8-x86_64-debug-rpms   Red Hat Ans disabled
ansible-2.9-for-rhel-8-x86_64-rpms         Red Hat Ans disabled
ansible-2.9-for-rhel-8-x86_64-source-rpms  Red Hat Ans disabled
-----------------
==== Enabling the repository

[source,bash]
-----------------
# subscription-manager repos --enable ansible-2.9-for-rhel-8-x86_64-rpms
-----------------

==== Installing Ansible and its dependencies
[source,bash]
-----------------
# yum install ansible -y
-----------------

==== Check everything is ok
[source,bash]
-----------------
# ansible --version
ansible 2.9.2
config file = /etc/ansible/ansible.cfg
onfigured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
ansible python module location = /usr/lib/python3.6/site-packages/ansible
executable location = /usr/bin/ansible
python version = 3.6.8 (default, Oct 11 2019, 15:04:54) [GCC 8.3.1 20190507 (Red Hat 8.3.1-4)]
-----------------

[NOTE]
In this stage, everything is set up for going forward and start automation!

== Enabling trust between Ansible control node and managed hosts
For speed up any of the actions proposed in this workshop we recommend to create a trust domain, which is easy to do following a simple steps.

==== Log in in the control node

When asks for password just press enter

[source,bash]
-----------------
# ssh-keygen -t rsa

Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:Ka1jUHpXm0z7fZ1fJYCWqU5ejMmkJWbyj63Cu44I49s root@controlnode
The key's randomart image is:
+---[RSA 3072]----+
|                 |
|           +     |
|    . = o B .    |
|     B B @ + .   |
|    o = S B   . .|
|     o @ . . . .+|
|o  .  = =   . ..+|
|oo..o. o       .o|
|.ooE++.         .|
+----[SHA256]-----+
-----------------

==== Copy the certificate on the managed host

[source,bash]
-----------------
# ssh-copy-id root@managedhost

/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@192.168.56.121's password:

Number of key(s) added: 1

Now try logging into the machine, with:   ssh root@192.168.56.121
and check to make sure that only the key(s) you wanted were added.
-----------------

[NOTE]
Now there is trust between control and managed host. We are ready for the next step.

== Checking everything is OK for start automating tasks

Our first task is to check if our control node is able to execute a module on the managed host. This is very simple executing an ad-hoc command.

From control node execute the following command replacing ipmanagedhosts with the IP address of your managed host

[source, bash]
-------------------
# ansible all -i 'ip_of_managed_hosts,' -m ping

ipmanagedhosts | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/libexec/platform-python"
    },
    "changed": false,
    "ping": "pong"
}
-------------------

An example with the ip 192.168.56.119 as the managed host.

[source, bash]
-------------------
# ansible all -i '192.168.56.119,' -m ping

192.168.56.119 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/libexec/platform-python"
    },
    "changed": false,
    "ping": "pong"
}
-------------------

[NOTE]
Look at the tag “ping” at the end of the JSON returned. If everything is ok, the result is “pong”

[NOTE]
Ping Module: This module is used to connect to the host, verify a usable python and return pong on success

== How Can I find a Module?

=== Modules are a fundamental part of Ansible
Modules do a variety of tasks that can be included in playbooks for automating complex procedures.

The best part of modules is that they are very well documented, so is a nice journey to go to the big list and see what they can do for us.
Accessing the module documentation
https://docs.ansible.com/ansible/latest/modules/modules_by_category.html 
Let’s find our first module

We can run ad-hoc commands on managed hosts with the module “command”. 

The module can be found at

https://docs.ansible.com/ansible/latest/modules/command_module.html?highlight=command


Let’s find out if the module cab me executed as an ad-hoc command

[source,bash]
--------------------
#  ansible all -i '192.168.56.119,' -m command -a "cat /etc/motd"

192.168.56.119 | CHANGED | rc=0 >>
  _____          _   _    _       _
 |  __ \        | | | |  | |     | |
 | |__) |___  __| | | |__| | __ _| |_
 |  _  // _ \/ _` | |  __  |/ _` | __|
 | | \ \  __/ (_| | | |  | | (_| | |_
 |_|  \_\___|\__,_| |_|  |_|\__,_|\__|
  _   _______ ____        _
 | | |__   __/ __ \      | |
 | |    | | | |  | |   __| | ___ _ __ ___   ___  ___
 | |    | | | |  | |  / _` |/ _ \ '_ ` _ \ / _ \/ __|
 | |____| | | |__| | | (_| |  __/ | | | | | (_) \__ \
 |______|_|  \____/   \__,_|\___|_| |_| |_|\___/|___/
--------------------

So Far So Good!

== Automating RHEL Administration

=== Why Automate my daily work?

It is a good question. There are several reasons why automation could save my life as an administrator.

But, let me be clear. My job is important as an administrator, and it could be even more important if I use my time and effort wisely to propose new ways of executing tasks making my company make more revenue. Isn't that be great?

We are going to look at the different perspectives why automation is so important as far as a RHEL administration is concerned.

=== Saving Time

First and foremost, automation can be used to save time. If I save time doing every day work, I can do more, but this is only the tip of the iceberg.

=== Get more control over my daily tasks

Having a tool that does exactly what it is supposed to do, all the time, could give administrators peace of mind doing repetitive configuration and deployment tasks. More control over my daily job with more confidence. 

=== Minimize errors

After a playbook is created and test it, it will be executed in exactly the same way, all the time. No human errors due to misspelled commands or enter key error.

=== Execute complex tasks in a consistent way

Every time a procedure is executed, no matter how complex it is, administrators could expect the same results, in one server or in a huge amount of them.

=== Scale in huge platforms

Ansible can assist to execute tasks in 1, 2 or n servers, locally or remotely located. The real power of ansible is the ability to delegate complex and extensive jobs to the angine in order to it to take care of the execution cna completion.
Document well my job

One of the nice features of ansible is that the output of every playbook executed could be used to document what happened in every run. This is a proof of execution that can be used to create more complex management document.

=== Get more confident in what I am doing in a production environment

When we often execute playbooks with predecible results every time, is natural to be confident about tasks otherwise need to be done manually and are prone to human errors.

== Configuring some defaults

For this workshop we need to create some defaults in order to have the basics to execute playbooks in a straightforward manner.

=== Creating the ansible path and inventory

[source,bash]
----------------------
# mkdir /root/ansible
# cd /root/ansible
# echo  $'[managedhosts] \nip_address' > inventory

The ipaddress must be replaced by the ip of the managed hosts. 

In the example below the ip address of the managed host in the lab is 192.168.56.119.

# echo  $'[managedhosts] \n192.168.56.119' > inventory

# more inventory
[managedhosts]
192.168.56.119
----------------------

== Automating an Application Deployment

=== Why?

Be repeatable when an application deployment is concern is crucial to survive in this automated world, where virtualization and cloud naive applications have taken control of a lot of aspects of our data centers.

Having the ability to deploy complex layouts and architectures in a virtualized environment, on-premise or not, is part of being at the speed of the 4th revolution.

Automated scalability in much cases is the name of the game, so whether it is the first time the application is deployed or several instances are needed to keep up with the demand, we need tools that keep us apart from the time consuming and error prone manual tasks.

This workshop has the main goal of showing you how to use ansible to deploy an application, from the RHEL management perspective.

Let’s get our hands dirty from now on...

=== The application

For this workshop we are going to implement a simple yet powerful general purpose application that could be used for multiple purposes. This app is a simple service provider that can be customized for any requirement in which exists the necessity of access the services to obtain something… bare with me, so I am going to explain this in detail.

=== The architecture

image::apparchitecture.png[Architecture Diagram]

=== The webChat layer

This layer expose through the port 8080 a web interface to intercact with, also expose an api.

* https://server_ip:8080/chat redirect to the app
* https://server_ip:8080/api?chat&question= define a simple api to ask to the service

Needless to say that it need the engine up&running for working properly.

=== The engine layer

This layer expose through the port 9095 via linux sockets a chat service.

* server_ip:9095/chat can be interrogated with an ansible question.

This service is essetial for the webChat layer to work properly.

=== Download the BOT src in the control host

[source,bash]
----------------------
# cd /root/ansible/
# git clone https://github.com/ltoRhelDemos/python-ansible-chatbot.git
----------------------

In the python-ansible-chatbot/ directory there are to python executable files.

* serviceProvider.py, which is the ansible chatbot engine.

* webChat.py, which is the web interface for accessing the service or to use the exposed restful API.

=== Creating the disk facilities for installing the application

We need to copy the source code to our managed hosts. Every managed host has 2 devices on /dev for creating a volume group. Such is the case of:

- /dev/sdb
- /dev/sdc

We need to create a volume group out of these two devices. This volume group will be named as *chatbotVG*. Inside this volume group we are going to create a logical volume named *data*. This logical volume will be mounted in a directory called /home/chatbot. This needs to be translated to a Playbook for automating this OS admin tasks in a consistend way.

Let´s start by checking that boths devices are present

[source,bash]
---------------------
---
  - hosts: managedhosts

    tasks:

      - name: check sdb
        block:
          - name: checking for device /dev/sdb
            set_fact: proceedWithInstallation=yes
            when:  hostvars[inventory_hostname]["ansible_facts"]["device_links"]["ids"]["sdb"] 
        rescue:
          - name: Device /dev/sdb does not exists!
            set_fact: proceedWithInstallation=no
          

      - name: check sdc
        block:
          - name: checking for device /dev/sdc
            set_fact: proceedWithInstallation=yes
            when:  hostvars[inventory_hostname]["ansible_facts"]["device_links"]["ids"]["sdc"] 
        rescue:
          - name: Device /dev/sdc does not exists!
            set_fact: proceedWithInstallation=no
        when:
          - hostvars[inventory_hostname]['proceedWithInstallation']
...
---------------------

Here we have coded a Block. A block able us to manage errors easily. We start with hosts: managedhosts as in inventory file has been set. For each IP address present in the group managedhosts ansible will execute the actions after the tasks tag is implemented.

We are going to check the hostvars content, which is populated when the gather_facts module is automatically executed. In this case we are checking the value of the dictionary with hostvars[inventory_hostname]["ansible_facts"]["device_links"]["ids"]["sdb"] to determine if sdb exists.

In case one or both devices are not present, a fact is created called "proceedWithInstallation" that will be useful to execute the rest of our playbook. If this variable is set to no, further installation won't be executed.

After we check the existance of our devices we proceed to create the volume group and logical volume to be mounted.

[source,bash]
--------------------
...
      - name: creating disk facilities
        block:
          - name: Creating chatbot Volume group.
            lvg:
              pvs: "/dev/sdb,/dev/sdc"
              vg: "chatbotVG"
              pesize: '8'
              pv_options: '-Z y'
              force: no
              state: present

          - name: Creating data Logical Volume.
            lvol:
              vg: "chatbotVG"
              lv: "data"
              size: 4g
              active: yes
              force: no
              state: present

          - name: Creating a XFS filesystem on lvm /dev/mapper/chatbotVG-data.
            filesystem:
              fstype: "xfs"
              dev: "/dev/mapper/chatbotVG-data"
              force: no

          - name: Creating the mounting point /home/chatbot.
            file:
              path: "/home/chatbot/"
              state: directory
              mode: '0700'

          - name: Mount the  filesystem.
            mount:
              path: "/home/chatbot"
              src: "/dev/mapper/chatbotVG-data"
              fstype: "xfs"
              opts: rw,nosuid,noexec
              state: mounted

        when:
          - hostvars[inventory_hostname]['proceedWithInstallation']

        
      - name: Showing disk management results
        debug: 
          msg: "An error occured when trying to create the disk facilities for the chatbot, aborting installation! {{hostvars[inventory_hostname]['proceedWithInstallation']}}"
        when:  
          - not hostvars[inventory_hostname]['proceedWithInstallation']          
--------------------
          
Another block is created with a *when clause* for execute the procedure if both devices are present. 

The playbook proceed with the following:

- Create a volume group called *chatbotVG* with sdc and sdc devices
- Create a logical volume called *data* which size is 4 Gb.
- Create a filesystem XFS on /dev/mapper/chatbotVG-data
- Create a mount point called */home/chatbot*
- Mount /dev/mapper/chatbotVG-data on /home/chatbot

=== installing the application dependencies.

The application needs python 3.6 installed in the managed host, so we need to create a playbook for installing the package, but also check and install the required libraries if needed. When we say "if needed" we refer ourselves to the fact that ansible is an idempotent tool. It will look to get to the desired stated (installed). If the package or the  libraries are already installed any of the actions assotiated will be executed.

Let's start for creating this playbook.

[NOTE] by now, we are creating independent Playbooks as big blocks as far as simplicity of explanation is concerned. Nevertheless at the end we will create a unique Playbook with all this isolated blocks for executing it in one piece.

[source,bash]
----------------------
# vim installChatBotPythonDependencies.yml

- hosts: managedhosts
  tasks:
  - name: install python 3.6
    yum:
      name: python36
      state: latest

  - name: install nltk
    pip:
      name: nltk

  - name: install numpy
    pip:
      name: numpy

  - name: install tflearn
    pip:
      name: tflearn

  - name: install tensorflow
    pip:
      name: tensorflow

  - name: install flask
    pip:
      name: flask

----------------------

The hosts to interact with are which are present in the managedhosts group of the inventory created previously. In our case is the IP Address 192.168.56.119.

Then we define the tasks that are going to be executed in this playbook. 

* At first place we need to be sure python 3.6 is installed, otherwise ansible needs to make sure the latest version is installed properly. This is done by the yum module which needs the package name (in this case python36 for RHEL 8.1) and the state. This flag tells ansible to install the package if not present or update it to the latest version if needed.

- name: python36
- state: latest

* The following actions are related to the installation of some required libraries. In this case nltk for natural language processing, numpy for numerical calculationsm, tflearn and tensorflow for applying artificial inteligence to the chatbot, and Flask for the creation of the web service delivered by webChat.py. The pip module only needs the name of the libraries that need to be installed.


[source,bash]
----------------------
# ansible-playbook installChatBotPythonDependencies.yml -i inventory

PLAY [managedhosts] ******************************************************************************************************************************************

TASK [Gathering Facts] ***************************************************************************************************************************************
ok: [192.168.56.119]

TASK [install python 3.6] ************************************************************************************************************************************
changed: [192.168.56.119]

TASK [install nltk] ******************************************************************************************************************************************
changed: [192.168.56.119]

TASK [install tflearn] ***************************************************************************************************************************************
changed: [192.168.56.119]

TASK [install tensorflow] ************************************************************************************************************************************
changed: [192.168.56.119]

TASK [install flask] *****************************************************************************************************************************************
changed: [192.168.56.119]

PLAY RECAP ***************************************************************************************************************************************************
192.168.56.119             : ok=6    changed=5    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

----------------------

This playbook was executed starting gathering facts. This module is automatically called by playbooks to gather useful variables about remote hosts that can be used in playbooks.

In fact, we can execute as an ad-hoc command using ansible. For example.

[source,bash]
----------------------
# ansible managedhosts -m gather_facts --tree /tmp/facts -i ./inventory

192.168.56.119 | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "10.0.2.15",
            "192.168.56.119",
            "192.168.122.1"
        ],
        "ansible_all_ipv6_addresses": [
            "fe80::a36:3b15:8f03:59a9",
            "fe80::7957:b5e7:19e1:e2ea",
            "fe80::5c76:f9ff:7511:26c7"
        ],
        "ansible_apparmor": {
            "status": "disabled"
        },
        "ansible_architecture": "x86_64",
        "ansible_bios_date": "12/01/2006",
        "ansible_bios_version": "VirtualBox",
        "ansible_cmdline": {
            "BOOT_IMAGE": "(hd0,msdos1)/vmlinuz-4.18.0-147.el8.x86_64",
            "quiet": true,
            "rd.lvm.lv": "rhel_yogurtu/swap",
            "resume": "/dev/mapper/rhel_yogurtu-swap",
            "rhgb": true,
            "ro": true,
            "root": "/dev/mapper/rhel_yogurtu-root"
        },
        "ansible_date_time": {
            "date": "2020-01-13",
            "day": "13",
            "epoch": "1578951976",
            "hour": "16",
            "iso8601": "2020-01-13T21:46:16Z",
...

 "ansible_virbr0_nic": {
            "active": false,
            "device": "virbr0-nic",
            "features": {
                "esp_hw_offload": "off [fixed]",
                "esp_tx_csum_hw_offload": "off [fixed]",
                "fcoe_mtu": "off [fixed]",
                "generic_receive_offload": "on",
                "generic_segmentation_offload": "on",
                "highdma": "off [fixed]",
                "hw_tc_offload": "off [fixed]",
                "l2_fwd_offload": "off [fixed]",
                "large_receive_offload": "off [fixed]",
                "loopback": "off [fixed]",
                "netns_local": "off [fixed]",
                "ntuple_filters": "off [fixed]",
                "receive_hashing": "off [fixed]",
                "rx_all": "off [fixed]",
                "rx_checksumming": "off [fixed]",
                "rx_fcs": "off [fixed]",
                "rx_gro_hw": "off [fixed]",
                "rx_udp_tunnel_port_offload": "off [fixed]",
                "rx_vlan_filter": "off [fixed]",
                "rx_vlan_offload": "off [fixed]",
                "rx_vlan_stag_filter": "off [fixed]",
                "rx_vlan_stag_hw_parse": "off [fixed]",
                "scatter_gather": "on",
                "tcp_segmentation_offload": "off",
                "tls_hw_record": "off [fixed]",
                "tls_hw_rx_offload": "off [fixed]",
                "tls_hw_tx_offload": "off [fixed]",
                "tx_checksum_fcoe_crc": "off [fixed]",
                "tx_checksum_ip_generic": "off [requested on]",
                "tx_checksum_ipv4": "off [fixed]",
                "tx_checksum_ipv6": "off [fixed]",
                "tx_checksum_sctp": "off [fixed]",
                "tx_checksumming": "off",
                "tx_esp_segmentation": "off [fixed]",
                "tx_fcoe_segmentation": "off [fixed]",
                "tx_gre_csum_segmentation": "off [fixed]",
                "tx_gre_segmentation": "off [fixed]",
                "tx_gso_partial": "off [fixed]",
                "tx_gso_robust": "off [fixed]",
                "tx_ipxip4_segmentation": "off [fixed]",
                "tx_ipxip6_segmentation": "off [fixed]",
                "tx_lockless": "on [fixed]",
                "tx_nocache_copy": "off",
                "tx_scatter_gather": "on",
                "tx_scatter_gather_fraglist": "on",
                "tx_sctp_segmentation": "off [fixed]",
                "tx_tcp6_segmentation": "off [requested on]",
                "tx_tcp_ecn_segmentation": "off [requested on]",
                "tx_tcp_mangleid_segmentation": "off",
                "tx_tcp_segmentation": "off [requested on]",
                "tx_udp_segmentation": "off [fixed]",
                "tx_udp_tnl_csum_segmentation": "off [fixed]",
                "tx_udp_tnl_segmentation": "off [fixed]",
                "tx_vlan_offload": "on",
                "tx_vlan_stag_hw_insert": "on",
                "vlan_challenged": "off [fixed]"
            },
            "hw_timestamp_filters": [],
            "macaddress": "52:54:00:14:f3:61",
            "mtu": 1500,
            "promisc": true,
            "timestamping": [
                "tx_software",
                "rx_software",
                "software"
            ],
            "type": "ether"
        },
        "ansible_virtualization_role": "guest",
        "ansible_virtualization_type": "virtualbox",
        "discovered_interpreter_python": "/usr/libexec/platform-python",
        "gather_subset": [
            "all"
        ],
        "module_setup": true
    },
    "changed": false
}

----------------------

Then it continues with the actions associated with libraries installation using the module pip. Each one is in charge of taking the library to the state desired, by default is "installed".

At the end of the execution output you can notice a PLAY RECAP, which in turns indicates that 5 things were changed, in this case the installation of python 3.6 and the installation of nlt, tflearn, tensorflow and flask libraries.

[source,bash]
----------------------
PLAY RECAP ***************************************************************************************************************************************************
192.168.56.119             : ok=6    changed=5    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
----------------------

In this stage we are sure all re pre-requisites are met to starting to create the directories where our software will be installed.

=== Installing the software in its final destination

For this, we have cloned the chatbot repository from github in python-ansible-chatbot directory. This directory contains all the sources and data needed to execute out service.

The following Playbook syncronize the content of this directory with the remote /home/chatbot directory. Then all the necesary ports are openned for the free access to the service.

[source,bash]
----------------------
# vim chatbotSyncSoftware.yml

---
  - hosts: managedhosts

    tasks:
    - name: copying chatbot software to chatbot servers 
      synchronize:
        src:  python-ansible-chatbot/
        dest: /home/chatbot/

    - name: Openning the webservice port 8080
      firewalld:
        port: 8080/tcp
        permanent: yes
        state: enabled

    - name: Openning the engine port 9095
      firewalld:
        port: 9095/tcp
        permanent: yes
        state: enabled

    - name: restarting the firewalld
      service:
        name: firewalld
        state: restarted
----------------------

The first part copy all the software to the remote directory using the module Syncronize wich use rsync to do its magic. Then the ports 8080 and 9095 are opened uding the module firewalld wich needs the port, the protocol and if the action will be permanent. At the end we restart the firewall service util de module service.

[source,bash]
----------------------
# ansible-playbook chatbotSyncSoftware.yml -i ./inventory

PLAY [managedhosts] ******************************************************************************************************************************************

TASK [Gathering Facts] ***************************************************************************************************************************************
ok: [192.168.56.119]

TASK [copying chatbot software to chatbot servers] ***********************************************************************************************************
changed: [192.168.56.119]

TASK [Openning the webservice port 8080] *********************************************************************************************************************
changed: [192.168.56.119]

TASK [Openning the engine port 9095] *************************************************************************************************************************
changed: [192.168.56.119]

TASK [restarting the firewalld] ******************************************************************************************************************************
changed: [192.168.56.119]

PLAY RECAP ***************************************************************************************************************************************************
192.168.56.119             : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

----------------------

The playbook is executed without any inconvienience.

Now our application is in the managed host ready to be executed to service a chatbot app. Let's first try to execute manually the engine on the managed host.

[source,bash]
----------------------
# ssh root@192.168.56.119

# cd /home/chatbot

# python3 serviceProvider.py

--------------------------------------------------------------------------

  _____          _   _    _       _
 |  __ \        | | | |  | |     | |
 | |__) |___  __| | | |__| | __ _| |_
 |  _  // _ \/ _` | |  __  |/ _` | __|
 | | \ \  __/ (_| | | |  | | (_| | |_
 |_|  \_\___|\__,_| |_|  |_|\__,_|\__|

  Service Provider Demo
  Alejandro Dirgan 2019


--------------------------------------------------------------------------
HELP:
--------------------------------------------------------------------------
to start server using other than default values use it with the paramaters:
   serviceProvider.py [port=9095] [homedir=/tmp] [serviceName=serviceProvider] [verbose=True]

to stop the server:
   touch /tmp/serviceProvider.stop

to send command to server via command line where 0.0.0.0 is the ip (localhost)
   echo about | nc 0.0.0.0 9095

--------------------------------------------------------------------------
INFO:
--------------------------------------------------------------------------
True
/tmp/serviceProvider.pid
(init) starting serviceProvider!
(init) home directory is /tmp
(init) listening on port 9095
(init) this process is identified by: 14813
Found data preprocessed on disk!
found model on disk!
(eventLoop) entering event loop!

----------------------

From the control host we can try to access the engine with Ncat command.

[source,bash]
----------------------
# echo chat question=who_are_you? | nc 192.168.56.119 9095

{"status": "(OK)", "response": {"tag": "who", "answer": "I am a robot that answers questions about Ansible"}}

# echo chat question=who_are_you? | nc 192.168.56.119 9095

{"status": "(OK)", "response": {"tag": "who", "answer": "I am a good chatter, specially if we talk about Ansible"}}

# echo chat question=are_you_a_robot? | nc 192.168.56.119 9095

{"status": "(OK)", "response": {"tag": "who", "answer": "I am a robot that answers questions about Ansible"}}

----------------------

As you can see the engine is able to classify your questions and respond accordingly. 

Let's try the web interface so we can be sure everything is ok so far.

In another ssh session to the managed host start the webChat.py program.

[source,bash]
----------------------
# cd /home/chatbot

# python3 webChat.py

 * Serving Flask app "webChat" (lazy loading)
 * Environment: production
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 306-602-425
192.168.56.1 - - [14/Jan/2020 17:22:35] "GET / HTTP/1.1" 200 -
192.168.56.1 - - [14/Jan/2020 17:22:35] "GET /favicon.ico HTTP/1.1" 404 -

----------------------

For accessing the service, just start a browser and type http://192.168.56.119:8080/chat

image::webChat.png[Ansible chatbot Web Interface]








